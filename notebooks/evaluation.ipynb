{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Change native directory to root\n",
    "os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from src.utils.functions import validation\n",
    "\n",
    "random.seed(123)\n",
    "model_dir = 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_list = glob.glob('./data/buildings/*.csv')\n",
    "test_list = random.sample(build_list, int(len(build_list) * 0.1))\n",
    "train_list = [x for x in build_list if x not in test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/buildings/226.csv',\n",
       " './data/buildings/170.csv',\n",
       " './data/buildings/119.csv',\n",
       " './data/buildings/1104.csv',\n",
       " './data/buildings/1453.csv',\n",
       " './data/buildings/1488.csv',\n",
       " './data/buildings/760.csv',\n",
       " './data/buildings/866.csv',\n",
       " './data/buildings/1713.csv',\n",
       " './data/buildings/1250.csv',\n",
       " './data/buildings/1299.csv',\n",
       " './data/buildings/1061.csv',\n",
       " './data/buildings/914.csv',\n",
       " './data/buildings/529.csv',\n",
       " './data/buildings/297.csv',\n",
       " './data/buildings/232.csv',\n",
       " './data/buildings/920.csv',\n",
       " './data/buildings/221.csv',\n",
       " './data/buildings/1311.csv',\n",
       " './data/buildings/250.csv',\n",
       " './data/buildings/1276.csv',\n",
       " './data/buildings/1353.csv',\n",
       " './data/buildings/1715.csv',\n",
       " './data/buildings/1116.csv',\n",
       " './data/buildings/917.csv',\n",
       " './data/buildings/762.csv',\n",
       " './data/buildings/163.csv',\n",
       " './data/buildings/1631.csv',\n",
       " './data/buildings/956.csv',\n",
       " './data/buildings/43.csv',\n",
       " './data/buildings/59.csv',\n",
       " './data/buildings/1513.csv',\n",
       " './data/buildings/331.csv',\n",
       " './data/buildings/1186.csv',\n",
       " './data/buildings/1739.csv',\n",
       " './data/buildings/659.csv',\n",
       " './data/buildings/1054.csv',\n",
       " './data/buildings/924.csv',\n",
       " './data/buildings/383.csv',\n",
       " './data/buildings/1516.csv',\n",
       " './data/buildings/503.csv',\n",
       " './data/buildings/1408.csv',\n",
       " './data/buildings/1654.csv',\n",
       " './data/buildings/1427.csv',\n",
       " './data/buildings/444.csv',\n",
       " './data/buildings/1008.csv',\n",
       " './data/buildings/506.csv',\n",
       " './data/buildings/197.csv',\n",
       " './data/buildings/213.csv',\n",
       " './data/buildings/1552.csv',\n",
       " './data/buildings/1425.csv',\n",
       " './data/buildings/1230.csv',\n",
       " './data/buildings/553.csv',\n",
       " './data/buildings/1533.csv',\n",
       " './data/buildings/139.csv',\n",
       " './data/buildings/1521.csv',\n",
       " './data/buildings/1138.csv',\n",
       " './data/buildings/1672.csv',\n",
       " './data/buildings/560.csv',\n",
       " './data/buildings/662.csv',\n",
       " './data/buildings/107.csv',\n",
       " './data/buildings/1202.csv',\n",
       " './data/buildings/188.csv',\n",
       " './data/buildings/1000.csv',\n",
       " './data/buildings/446.csv',\n",
       " './data/buildings/759.csv',\n",
       " './data/buildings/1602.csv',\n",
       " './data/buildings/1512.csv',\n",
       " './data/buildings/1284.csv',\n",
       " './data/buildings/923.csv',\n",
       " './data/buildings/1015.csv',\n",
       " './data/buildings/493.csv',\n",
       " './data/buildings/1632.csv',\n",
       " './data/buildings/1024.csv',\n",
       " './data/buildings/845.csv',\n",
       " './data/buildings/35.csv',\n",
       " './data/buildings/1042.csv',\n",
       " './data/buildings/815.csv',\n",
       " './data/buildings/657.csv',\n",
       " './data/buildings/1426.csv',\n",
       " './data/buildings/311.csv',\n",
       " './data/buildings/148.csv',\n",
       " './data/buildings/210.csv',\n",
       " './data/buildings/1159.csv',\n",
       " './data/buildings/1078.csv',\n",
       " './data/buildings/1327.csv',\n",
       " './data/buildings/1549.csv',\n",
       " './data/buildings/76.csv',\n",
       " './data/buildings/1121.csv',\n",
       " './data/buildings/1570.csv',\n",
       " './data/buildings/1251.csv',\n",
       " './data/buildings/687.csv',\n",
       " './data/buildings/187.csv',\n",
       " './data/buildings/934.csv',\n",
       " './data/buildings/819.csv',\n",
       " './data/buildings/1396.csv',\n",
       " './data/buildings/609.csv',\n",
       " './data/buildings/582.csv',\n",
       " './data/buildings/791.csv',\n",
       " './data/buildings/1191.csv',\n",
       " './data/buildings/1132.csv',\n",
       " './data/buildings/1245.csv',\n",
       " './data/buildings/1294.csv',\n",
       " './data/buildings/563.csv',\n",
       " './data/buildings/556.csv',\n",
       " './data/buildings/485.csv',\n",
       " './data/buildings/51.csv',\n",
       " './data/buildings/1555.csv',\n",
       " './data/buildings/1278.csv',\n",
       " './data/buildings/194.csv',\n",
       " './data/buildings/272.csv',\n",
       " './data/buildings/1364.csv',\n",
       " './data/buildings/1162.csv',\n",
       " './data/buildings/108.csv',\n",
       " './data/buildings/1733.csv',\n",
       " './data/buildings/854.csv',\n",
       " './data/buildings/525.csv',\n",
       " './data/buildings/259.csv',\n",
       " './data/buildings/1719.csv',\n",
       " './data/buildings/868.csv',\n",
       " './data/buildings/1204.csv',\n",
       " './data/buildings/1671.csv',\n",
       " './data/buildings/1136.csv',\n",
       " './data/buildings/1112.csv',\n",
       " './data/buildings/995.csv',\n",
       " './data/buildings/705.csv',\n",
       " './data/buildings/793.csv',\n",
       " './data/buildings/269.csv',\n",
       " './data/buildings/1685.csv',\n",
       " './data/buildings/701.csv',\n",
       " './data/buildings/159.csv',\n",
       " './data/buildings/855.csv',\n",
       " './data/buildings/1615.csv',\n",
       " './data/buildings/736.csv',\n",
       " './data/buildings/365.csv',\n",
       " './data/buildings/904.csv',\n",
       " './data/buildings/138.csv',\n",
       " './data/buildings/808.csv',\n",
       " './data/buildings/1063.csv',\n",
       " './data/buildings/1712.csv',\n",
       " './data/buildings/824.csv',\n",
       " './data/buildings/1600.csv',\n",
       " './data/buildings/524.csv',\n",
       " './data/buildings/704.csv',\n",
       " './data/buildings/411.csv',\n",
       " './data/buildings/397.csv',\n",
       " './data/buildings/867.csv',\n",
       " './data/buildings/284.csv',\n",
       " './data/buildings/430.csv',\n",
       " './data/buildings/1040.csv',\n",
       " './data/buildings/1009.csv',\n",
       " './data/buildings/947.csv',\n",
       " './data/buildings/782.csv',\n",
       " './data/buildings/600.csv',\n",
       " './data/buildings/104.csv',\n",
       " './data/buildings/595.csv',\n",
       " './data/buildings/1163.csv',\n",
       " './data/buildings/667.csv',\n",
       " './data/buildings/680.csv',\n",
       " './data/buildings/1259.csv',\n",
       " './data/buildings/816.csv',\n",
       " './data/buildings/1450.csv',\n",
       " './data/buildings/1664.csv',\n",
       " './data/buildings/1268.csv',\n",
       " './data/buildings/319.csv',\n",
       " './data/buildings/1225.csv',\n",
       " './data/buildings/1226.csv',\n",
       " './data/buildings/326.csv',\n",
       " './data/buildings/1710.csv',\n",
       " './data/buildings/1126.csv',\n",
       " './data/buildings/342.csv',\n",
       " './data/buildings/570.csv',\n",
       " './data/buildings/1221.csv',\n",
       " './data/buildings/1305.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearly</th>\n",
       "      <th>weekend</th>\n",
       "      <th>evening</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.071996</td>\n",
       "      <td>0.295865</td>\n",
       "      <td>0.541792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.022563</td>\n",
       "      <td>0.130884</td>\n",
       "      <td>0.326180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>0.116772</td>\n",
       "      <td>0.190230</td>\n",
       "      <td>0.348661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>0.008973</td>\n",
       "      <td>0.146399</td>\n",
       "      <td>0.396827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>0.096520</td>\n",
       "      <td>0.213343</td>\n",
       "      <td>0.530799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.586307</td>\n",
       "      <td>0.221625</td>\n",
       "      <td>0.362090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>0.213859</td>\n",
       "      <td>0.171083</td>\n",
       "      <td>0.270924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.269399</td>\n",
       "      <td>0.386193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>0.235348</td>\n",
       "      <td>0.256797</td>\n",
       "      <td>0.615815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.073034</td>\n",
       "      <td>0.188432</td>\n",
       "      <td>0.388656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        yearly   weekend   evening\n",
       "666   0.071996  0.295865  0.541792\n",
       "399   0.022563  0.130884  0.326180\n",
       "1544  0.116772  0.190230  0.348661\n",
       "1655  0.008973  0.146399  0.396827\n",
       "844   0.096520  0.213343  0.530799\n",
       "...        ...       ...       ...\n",
       "320   0.586307  0.221625  0.362090\n",
       "944   0.213859  0.171083  0.270924\n",
       "444   0.004852  0.269399  0.386193\n",
       "778   0.235348  0.256797  0.615815\n",
       "986   0.073034  0.188432  0.388656\n",
       "\n",
       "[81 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the features from the csv file\n",
    "features = pd.read_csv('data/social_features_test.csv', index_col=0)\n",
    "# read metadata csv\n",
    "metadata = pd.read_csv('data/EANLIJST_METADATA.csv', index_col=0, sep   = ';')\n",
    "# ADD the functietype column to the features\n",
    "features['function'] = metadata['Patrimonium Functietype']\n",
    "# read more metrics from csv\n",
    "features.isnull().sum()\n",
    "features.dropna(inplace=True)\n",
    "features['ID'] = features.index\n",
    "# drop rows with kast as function\n",
    "features = features[features['function'] != 'Kast']\n",
    "features['morning'] = features.iloc[:,4:16].sum(axis=1)\n",
    "features['evening'] = features.iloc[:,np.r_[:4,16:24]].sum(axis=1)\n",
    "features['weekday'] = features.iloc[:,24:29].sum(axis=1)\n",
    "features['weekend'] = features.iloc[:,29:31].sum(axis=1)\n",
    "# scale yearly column to 0-1 with minmax scaler\n",
    "subset = features[['yearly', 'weekend',  'evening']].copy()\n",
    "subset['yearly'] = MinMaxScaler().fit_transform(subset['yearly'].values.reshape(-1,1))\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_num = 10\n",
    "kmeans = pickle.load(open(model_dir+\"kmeans{}.pkl\".format(clust_num),  \"rb\"))\n",
    "clusters = kmeans.predict(subset)\n",
    "features['cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:15:00</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:30:00</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:45:00</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:15:00</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 23:00:00</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 23:15:00</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 23:30:00</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 23:45:00</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01 00:00:00</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105216 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1         2         3         4  \\\n",
       "ds                                                                      \n",
       "2019-01-01 00:15:00  0.000019  0.000017  0.000024  0.000021  0.000012   \n",
       "2019-01-01 00:30:00  0.000019  0.000018  0.000024  0.000023  0.000012   \n",
       "2019-01-01 00:45:00  0.000019  0.000017  0.000024  0.000022  0.000012   \n",
       "2019-01-01 01:00:00  0.000019  0.000018  0.000024  0.000021  0.000012   \n",
       "2019-01-01 01:15:00  0.000019  0.000018  0.000023  0.000021  0.000012   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2021-12-31 23:00:00  0.000019  0.000017  0.000019  0.000022  0.000013   \n",
       "2021-12-31 23:15:00  0.000019  0.000016  0.000018  0.000022  0.000013   \n",
       "2021-12-31 23:30:00  0.000018  0.000017  0.000018  0.000022  0.000013   \n",
       "2021-12-31 23:45:00  0.000018  0.000016  0.000018  0.000022  0.000013   \n",
       "2022-01-01 00:00:00  0.000018  0.000017  0.000018  0.000022  0.000013   \n",
       "\n",
       "                            5         6         7         8         9  \n",
       "ds                                                                     \n",
       "2019-01-01 00:15:00  0.000055  0.000020  0.000019  0.000028  0.000007  \n",
       "2019-01-01 00:30:00  0.000053  0.000020  0.000020  0.000029  0.000007  \n",
       "2019-01-01 00:45:00  0.000047  0.000020  0.000019  0.000029  0.000008  \n",
       "2019-01-01 01:00:00  0.000046  0.000020  0.000019  0.000029  0.000007  \n",
       "2019-01-01 01:15:00  0.000046  0.000020  0.000021  0.000029  0.000007  \n",
       "...                       ...       ...       ...       ...       ...  \n",
       "2021-12-31 23:00:00  0.000028  0.000019  0.000015       inf  0.000011  \n",
       "2021-12-31 23:15:00  0.000028  0.000019  0.000013  0.000020  0.000009  \n",
       "2021-12-31 23:30:00  0.000027  0.000019  0.000013       inf  0.000008  \n",
       "2021-12-31 23:45:00  0.000027  0.000019  0.000013       inf  0.000010  \n",
       "2022-01-01 00:00:00  0.000025  0.000019  0.000013       inf  0.000010  \n",
       "\n",
       "[105216 rows x 10 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles = pd.read_csv('./data/st_p_kmeans{}.csv'.format(clust_num), index_col=0)\n",
    "profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = features[['yearly', 'weekend',  'evening']].copy()\n",
    "mae = {}\n",
    "rmse = {}\n",
    "smape = {}\n",
    "for ID in features.index:\n",
    "    ts = pd.read_csv('./data/buildings/{}.csv'.format(ID), usecols=['Power', 'ds'], index_col='ds')\n",
    "    #print(ts)\n",
    "    clust_ts = kmeans.predict(np.array(subset.loc[ID]).reshape(1, -1))\n",
    "    ts_syn = profiles[str(clust_ts[0])].copy() * features.loc[ID, 'yearly']\n",
    "    # measure the error\n",
    "    mae[ID] = validation(ts.values, ts_syn, 'MAE')\n",
    "    rmse[ID] = validation(ts.values, ts_syn, 'RMSE')\n",
    "    smape[ID] = validation(ts.values, ts_syn, 'SMAPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of SMAPE: 29.68118999770497\n",
      "Mean of MAE: 7.094519138069932\n",
      "Mean of RMSE: 9.6445259395783\n"
     ]
    }
   ],
   "source": [
    "# mean of smape dict values\n",
    "mean_smape = np.mean(list(smape.values()))\n",
    "# mean of mae dict values\n",
    "mean_mae = np.mean(list(mae.values()))\n",
    "# mean of rmse dict values\n",
    "mean_rmse = np.mean(list(rmse.values()))\n",
    "print(\"Mean of SMAPE: {}\".format(mean_smape))\n",
    "print(\"Mean of MAE: {}\".format(mean_mae))\n",
    "print(\"Mean of RMSE: {}\".format(mean_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clust_num in [10,11,12]:\n",
    "    kmeans = pickle.load(open(model_dir+\"kmeans{}.pkl\".format(clust_num),  \"rb\"))\n",
    "    subset = features[['yearly', 'weekend',  'evening']].copy()\n",
    "    clusters = kmeans.predict(subset)\n",
    "    features['cluster'] = clusters\n",
    "    profiles = pd.DataFrame()\n",
    "    # Create stanard profiles for each cluster\n",
    "    for k, clust in enumerate(range(clust_num)):\n",
    "        agg = pd.DataFrame()\n",
    "        for i, ID in enumerate(features[features.cluster == clust].index):\n",
    "            agg[ID] = pd.read_csv('./data/buildings/' + str(ID) + '.csv', index_col=0, usecols=['ds','Power'], parse_dates=['ds'])\n",
    "            agg[ID] = agg[ID] / agg[ID].resample('A').sum().values[0]\n",
    "        # drop the rows with any infinite values\n",
    "        agg = agg[~np.isinf(agg).any(1)]\n",
    "        # Create an average profile over columns\n",
    "        agg = agg.mean(axis=1)\n",
    "        profiles[clust] = agg\n",
    "    mae = {}\n",
    "    rmse = {}\n",
    "    smape = {}\n",
    "    for ID in features.index:\n",
    "        ts = pd.read_csv('./data/buildings/{}.csv'.format(ID), usecols=['Power', 'ds'], index_col='ds')\n",
    "        #print(ts)\n",
    "        clust_ts = kmeans.predict(np.array(subset.loc[ID]).reshape(1, -1))\n",
    "        ts_syn = profiles[str(clust_ts[0])].copy() * features.loc[ID, 'yearly']\n",
    "        # measure the error\n",
    "        mae[ID] = validation(ts.values, ts_syn, 'MAE')\n",
    "        rmse[ID] = validation(ts.values, ts_syn, 'RMSE')\n",
    "        smape[ID] = validation(ts.values, ts_syn, 'SMAPE')\n",
    "    # make a dataframe with 3 dictionaries as columns\n",
    "    temp_df = pd.DataFrame({'MAE': mae, 'RMSE': rmse, 'SMAPE': smape})\n",
    "    temp_df.to_csv('./results/kmeans{}.csv'.format(clust_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through csv files in the results folder and calculate the mean of each column\n",
    "mean_df = pd.DataFrame()\n",
    "for file in os.listdir('./results/'):\n",
    "    if file.endswith(\".csv\"):\n",
    "        temp_df = pd.read_csv('./results/' + file)\n",
    "        mean_df[file] = temp_df.mean(axis=0)\n",
    "mean_df.drop('Unnamed: 0', axis=0, inplace=True)\n",
    "mean_df.drop('mean_results.csv', axis=1, inplace=True)\n",
    "mean_df = mean_df.T\n",
    "mean_df['order'] = mean_df.index.map(split_index)\n",
    "mean_df.sort_values('order', inplace=True)\n",
    "mean_df.drop('order', axis=1, inplace=True)\n",
    "mean_df.to_csv('./results/mean_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile('([a-z]+)(\\d*)', re.I)\n",
    "def split_index(idx):\n",
    "    m = pattern.match(idx)\n",
    "    if m:\n",
    "        letters = m.group(1)\n",
    "        numbers = m.group(2)\n",
    "        if numbers:\n",
    "            return (letters, int(numbers))\n",
    "        else:\n",
    "            return (letters, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('vvsg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90a767557799bee2de1016a1437fac7679255ccc409d29b76a98294dd1a886c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
